import numpy as np  
import matplotlib.pyplot as plt 
import math

"""About this task:
I want to calculate ∫∫(x+2*y)*(x+y)dydx with bounds of (2,4) for y and (0,1) for x using Monte-Carlo integration.

I'm not going to thoroughly explain MC integration here, but we first rewrite the function as f(x,y)=g(x,y)p(x,y), where p(x,y) =(x+y)/7 and g(x,y) = 7(x+2y).
We need to generate random numbers on p(x,y), and to do this I generate a Markov chain using an algorithm called Metropolis.

Put simply, the Markov chain is a random walk on the number line where we pick a direction and then take a step if:
1. the number we're going to step to has a higher value on the pdf p(x,y) than the one we're currently at or...
2. if when we generate a uniform random number on (0,1) and the ratio of our proposed step location's pdf value to our current location's is greater than this random number.
Otherwise we stay put and generate a new proposed step.

If you think about these rules for a while you can convince yourself that we'll tend to hang out in locations where the pdf is high but still be able to wander to low pdf locations with decreasing odds the lower we go.
This sounds like we're approximating the pdf, and in fact, it can be shown that this is the case.

We throw out the first chunk (10%) of our Markov chain because our starting position is arbitrary and this throws off the random number generation, but after a while we settle into the pdf.

When ran this file prints off the exact value of this integration (which is 47) as well as the approximation generated by our MC integration
"""

#p(x,y) is a properly normalized pdf
N=10**5
#defines a proposition function as a random walk with stepsize on a uniform distribution from -1 to 1
def prop(x,y,step=1):
    xp=x+np.random.uniform(-step,step)
    yp=y+np.random.uniform(-step,step)
    return xp,yp
#define the pdf.  We are only integrating x in [0,1] and y in [2,4] so we set the pdf to 0 outside that range
def pdf(x,y):
    if x<0 or x>1:
        return 0
    elif y<2 or y>4:
        return 0
    else:
        return (x+y)/7.    
#implement metropolis algorithm to choose next x,y in markov chain
def getnext(x,y):
    #create proposition x,y
    xp=prop(x,y)[0]
    yp=prop(x,y)[1]
    #define the ratio of proposed location on pdf to current location
    rat=pdf(xp,yp)/pdf(x,y)
    #if proposed location has higher value for pdf accept proposition
    if rat>1:
        return xp,yp
    #else if the ratio of pdf values between proposed position and current position is greater than a randomly generated number on (0,1) accept proposition
    elif rat>np.random.uniform(0,1):
        return xp,yp 
    #else reject proposition and return current position
    else:
        return x,y 
#function to produce markov chain x0=1 y0=3
#really two related chains 1 for x and 1 for y because figuring out how to append elements one at a time to a specific sub-array of a numpy array was frustrating
def genchain(chainx=np.array([1.]),chainy=np.array([3.]),N=10**5):
    #primitive progress bar
    for i in range(N):
        if i%1000==0:
            print(str(math.floor(i/N*100))+'%')
        #get the last x,y pair added to chain
        currx=chainx[-1]
        curry=chainy[-1]
        #past pair into metropolis algorithm
        nextxy=getnext(currx,curry)
        #append result of metropolis to chain
        chainx=np.append(chainx,nextxy[0])
        chainy=np.append(chainy,nextxy[1])
    return chainx,chainy
#generate chains
chainxy=genchain()
chainx=chainxy[0]
chainy=chainxy[1]
#cut out the first 10% of chain for burn in
chainx=chainx[int(N/10):]
chainy=chainy[int(N/10):]

#use chain as random elements from pdf in Monte Carlo integration
def g(x,y):
    return 7*(2*y+x)

print('exact result=47, metropolis/MC result={}'.format(np.mean(g(chainx,chainy))))

#some 2d histograms used for checking if markov chain follows pdf
"""fig=plt.figure()
ax1=fig.add_subplot(111)
ax1.hist2d(chainxy[0],chainxy[1],bins=30)
plt.show()"""
